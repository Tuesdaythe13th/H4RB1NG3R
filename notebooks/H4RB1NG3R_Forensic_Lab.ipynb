{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "#@title ðŸ§  H4RB1NG3R v3.6: Multi-Persona Forensic Lab & Multimodal Scanner\n",
        "### **Principal Investigator:** Tuesday @ ARTIFEX Labs (The System Comptroller)\n",
        "#### **Sovereign Substrate for Mechanistic Diagnostics, Evidence Bundles, and Provenance Verification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "readme"
      },
      "source": [
        "#@title ðŸ“– Notebook README â€” ARTIFEX Labs\n",
        "\n",
        "**Notebook Goal:** Execute a lightweight end-to-end forensic audit of uploaded artifacts (text, images, audio), generate persona-based hypotheses, and output a tamper-evident evidence bundle.\n",
        "\n",
        "**What this notebook covers:**\n",
        "- Secure intake with metadata capture and minimal PII exposure.\n",
        "- Multimodal scanning (EXIF/metadata + signal analysis).\n",
        "- Multi-persona diagnosis for triangulated findings.\n",
        "- Evidence bundle generation for governance workflows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "working-components"
      },
      "source": [
        "#@title âœ… Working Components (Notebook Scope)\n",
        "\n",
        "**Detection & Analysis:**\n",
        "- Multimodal metadata extraction (images/audio).\n",
        "- Frequency-domain scanning for anomaly patterns.\n",
        "- Persona-based diagnosis for cross-checking conclusions.\n",
        "\n",
        "**Evidence & Governance Outputs:**\n",
        "- Evidence bundle assembly (timestamped, structured summary).\n",
        "- Redaction-ready reporting format for compliance review.\n",
        "\n",
        "**Interoperability:**\n",
        "- Designed to map into MCP tool outputs and external SIEM pipelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-intro"
      },
      "source": [
        "#@title ðŸ› ï¸ Phase 1: Environment + Artifex HTML Skin\n",
        "\n",
        "**Rationale:**\n",
        "We use `uv` awareness and quiet installs to avoid \"Colab Dependency Hell.\" This cell initializes the **System Comptroller**'s visual substrate using **Syne Mono** (Headers) and **Epilogue** (Body).\n",
        "\n",
        "**Technical Baseline:**\n",
        "- **Resolver:** `uv` (Fast, isolated).\n",
        "- **UI:** Brutalist HTML Explainers.\n",
        "- **Logging:** Emoji-prefixed temporal logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "setup-code"
      },
      "outputs": [],
      "source": [
        "#@title Environment + Artifex HTML Skin (Run First)\n",
        "import sys, os, re, json, math, time\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from IPython.display import display, HTML\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "def ts() -> str:\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "def log(msg: str, level: str = \"INFO\"):\n",
        "    icon = {\"INFO\": \":information_source:\", \"OK\": \":white_check_mark:\", \"WARN\": \":warning:\", \"ERR\": \":x:\", \"RUN\": \":rocket:\", \"LOCK\": \":lock:\"}.get(level, \":speech_balloon:\")\n",
        "    try: import emoji; print(f\"[{ts()}] {emoji.emojize(icon, language='alias')} {level}: {msg}\")\n",
        "    except: print(f\"[{ts()}] {level}: {msg}\")\n",
        "\n",
        "def quiet_install(packages: List[str]):\n",
        "    pkgs = \" \".join(packages)\n",
        "    log(f\"Installing dependencies: {pkgs}\", \"RUN\")\n",
        "    !pip install -q {pkgs}\n",
        "    log(\"Install complete.\", \"OK\")\n",
        "\n",
        "quiet_install([\n",
        "    \"emoji\", \"pandas\", \"numpy\", \"scikit-learn\", \"torch\", \"transformers\", \"datasets\", \n",
        "    \"pandera\", \"ydata-profiling\", \"loguru\", \"graphviz\", \"pydot\", \"tqdm\", \"ipywidgets\", \n",
        "    \"watermark\", \"plotly\", \"openai\", \"anthropic\", \"pillow\", \"opencv-python\", \n",
        "    \"exifread\", \"hachoir\", \"librosa\", \"soundfile\", \"filetype\", \"pymediainfo\"\n",
        "])\n",
        "\n",
        "ARTIFEX_CSS = \"\"\"\n",
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Syne+Mono&family=Epilogue:wght@300;400;600;800&display=swap');\n",
        ":root{ --ax-bg: #0b0c10; --ax-panel: #111218; --ax-border: #ffffff22; --ax-text: #f5f7ff; --ax-subtle: #b7bdc9; --ax-accent: #7df9ff; --ax-warn: #ffcc00; --ax-bad: #ff3366; }\n",
        ".artifex-root{ background: var(--ax-bg); color: var(--ax-text); border: 1px solid var(--ax-border); border-radius: 12px; padding: 16px 18px; font-family: 'Epilogue', sans-serif; line-height: 1.35; }\n",
        ".artifex-header{ font-family: 'Syne Mono', monospace; font-size: 34px; letter-spacing: 0.04em; margin: 0 0 6px 0; }\n",
        ".artifex-subhead{ font-family: 'Syne Mono', monospace; font-size: 12px; text-transform: uppercase; letter-spacing: 0.18em; color: var(--ax-subtle); margin: 0 0 14px 0; }\n",
        ".artifex-table{ width: 100%; border-collapse: collapse; margin-top: 10px; font-size: 13px; }\n",
        ".artifex-table th, .artifex-table td{ border: 1px solid var(--ax-border); padding: 8px 10px; }\n",
        ".artifex-table th{ background: #1a1c25; color: var(--ax-accent); font-weight: 700; }\n",
        ".badge{ display: inline-block; padding: 2px 8px; border-radius: 999px; border: 1px solid var(--ax-border); font-family: 'Syne Mono', monospace; font-size: 11px; margin-right: 6px; }\n",
        ".badge.ok{ color: var(--ax-accent); } .badge.warn{ color: var(--ax-warn); } .badge.bad{ color: var(--ax-bad); }\n",
        ".artifex-note{ color: var(--ax-subtle); font-size: 13px; margin-top: 10px; }\n",
        "hr.artifex-hr{ border: none; border-top: 1px dashed var(--ax-border); margin: 12px 0; }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "def artifex_header_html() -> str:\n",
        "    return f\"{ARTIFEX_CSS}<div class='artifex-root'><div class='artifex-header'>ARTIFEX LABS</div><div class='artifex-subhead'>{ts()} â€” H4RB1NG3R v3.6 â€” System Comptroller</div></div>\"\n",
        "\n",
        "def brutalist_explainer_html(title, table_html, interp_md, analysis_md, whitepapers) -> str:\n",
        "    wp_rows = \"\".join([f\"<tr><td>{i+1}</td><td>{n}</td><td>{r}</td></tr>\" for i,(n,r) in enumerate(whitepapers)])\n",
        "    return f\"\"\"\n",
        "    {ARTIFEX_CSS}<div class='artifex-root'>\n",
        "      <div class='artifex-header' style='font-size:22px;'>{title}</div>\n",
        "      <hr class='artifex-hr'/>\n",
        "      {table_html}\n",
        "      <hr class='artifex-hr'/>\n",
        "      <div style='font-weight:700; color: var(--ax-accent);'>Interpretation</div><div style='white-space: pre-wrap;'>{interp_md}</div>\n",
        "      <hr class='artifex-hr'/>\n",
        "      <div style='font-weight:700; color: var(--ax-accent);'>Analysis</div><div style='white-space: pre-wrap;'>{analysis_md}</div>\n",
        "      <hr class='artifex-hr'/>\n",
        "      <table class='artifex-table'><thead><tr><th>#</th><th>Whitepaper</th><th>Relevance</th></tr></thead><tbody>{wp_rows}</tbody></table>\n",
        "    </div>\"\"\"\n",
        "\n",
        "display(HTML(artifex_header_html()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intake-intro"
      },
      "source": [
        "#@title ðŸ“¥ Phase 2: Secure Intake & Multimodal Upload\n",
        "\n",
        "**Rationale:**\n",
        "Forensic audits require high context without PII leak. This cell collects anonymized data (Provider, Region, Gen-Settings) and handles the literal bits of images/audio/video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "intake-widget"
      },
      "outputs": [],
      "source": [
        "#@title Intake Widget + Multimodal Upload\n",
        "import ipywidgets as widgets\n",
        "from google.colab import files\n",
        "\n",
        "CASE_CONTEXT = {}\n",
        "UPLOADED_FILES = {}\n",
        "\n",
        "dropdowns = {\n",
        "    \"provider\": widgets.Dropdown(options=[\"OpenAI\", \"Anthropic\", \"Google\", \"Other\"], description=\"Provider:\"),\n",
        "    \"surface\": widgets.Dropdown(options=[\"API\", \"Web Chat\", \"Mobile App\", \"3rd-party\"], description=\"Surface:\")\n",
        "}\n",
        "text_inputs = {\n",
        "    \"browser\": widgets.Text(description=\"Browser/App:\"),\n",
        "    \"country\": widgets.Text(description=\"Country:\"),\n",
        "    \"model\": widgets.Text(description=\"Model Name:\")\n",
        "}\n",
        "btn_save = widgets.Button(description=\"Save Case Context\", button_style=\"primary\")\n",
        "btn_upload = widgets.Button(description=\"Upload Artifacts\", button_style=\"success\")\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_save(_):\n",
        "    global CASE_CONTEXT\n",
        "    with out: \n",
        "        CASE_CONTEXT = {k: v.value for k, v in {**dropdowns, **text_inputs}.items()}\n",
        "        log(\"Context saved (Anonymized).\", \"OK\")\n",
        "\n",
        "def on_upload(_):\n",
        "    global UPLOADED_FILES\n",
        "    with out:\n",
        "        uploaded = files.upload()\n",
        "        UPLOADED_FILES.update(uploaded)\n",
        "        log(f\"Uploaded {len(uploaded)} files.\", \"OK\")\n",
        "\n",
        "btn_save.on_click(on_save)\n",
        "btn_upload.on_click(on_upload)\n",
        "display(*dropdowns.values(), *text_inputs.values(), btn_save, btn_upload, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scanner-intro"
      },
      "source": [
        "#@title ðŸ“¡ Phase 3: Multimodal Forensic Scanner\n",
        "\n",
        "**Scanning Vectors:**\n",
        "1. **Metadata:** EXIF, Hachoir, FFProbe.\n",
        "2. **Signals:** FFT High-Freq Analysis (Watermark Heuristic).\n",
        "3. **Anomalies:** Detection of re-encoding tags, clipping, or suspicious software strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "scanner-code"
      },
      "outputs": [],
      "source": [
        "#@title Core Multimodal Scanners\n",
        "import filetype, exifread, cv2, librosa, hashlib\n",
        "from PIL import Image\n",
        "import soundfile as sf\n",
        "from hachoir.parser import createParser\n",
        "from hachoir.metadata import extractMetadata\n",
        "\n",
        "def sha256_b(b): return hashlib.sha256(b).hexdigest()\n",
        "\n",
        "def fft_scan_gray(img_bytes):\n",
        "    img = Image.open(io.BytesIO(img_bytes)).convert(\"L\")\n",
        "    arr = np.array(img)\n",
        "    f = np.fft.fftshift(np.fft.fft2(arr.astype(float)))\n",
        "    mag = np.log1p(np.abs(f))\n",
        "    h, w = mag.shape\n",
        "    center = mag[h//2-10:h//2+10, w//2-10:w//2+10]\n",
        "    return {\"fft_ratio\": float(np.mean(mag) / (np.mean(center) + 1e-9))}\n",
        "\n",
        "def scan_file(name, b):\n",
        "    kind = filetype.guess(b)\n",
        "    mime = kind.mime if kind else \"unknown\"\n",
        "    res = {\"identity\": {\"name\": name, \"mime\": mime, \"hash\": sha256_b(b)}, \"flags\": []}\n",
        "    \n",
        "    if mime.startswith(\"image\"):\n",
        "        try: res[\"extra\"] = fft_scan_gray(b)\n",
        "        except: pass\n",
        "    \n",
        "    # Anomaly Heuristics\n",
        "    if b\"FFMPEG\" in b: res[\"flags\"].append(\"VID_ENCODER_FFMPEG_DETECTED\")\n",
        "    if b\"Photoshop\" in b: res[\"flags\"].append(\"META_SOFTWARE_PHOTOSHOP\")\n",
        "    \n",
        "    return res\n",
        "\n",
        "log(\"Scanner initialized.\", \"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diagnosis-intro"
      },
      "source": [
        "#@title ðŸ§ Phase 4: Multi-Persona Diagnosis\n",
        "\n",
        "**Personas:**\n",
        "- **Forensic Analyst:** Integrity & Provenance.\n",
        "- **Signal Processor:** Frequency-domain watermarking.\n",
        "- **Privacy Counsel:** PII minimization.\n",
        "- **Adversarial ML:** Jailbreak & steering detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "diagnosis-code"
      },
      "outputs": [],
      "source": [
        "#@title Generate Persona Hypotheses\n",
        "def get_diagnosis(records):\n",
        "    diagnosis = []\n",
        "    for r in records:\n",
        "        art_diag = {\"name\": r[\"identity\"][\"name\"], \"hypotheses\": []}\n",
        "        if \"VID_ENCODER_FFMPEG_DETECTED\" in r[\"flags\"]:\n",
        "            art_diag[\"hypotheses\"].append(\"[Forensic] Possible re-encoding or synthetic video pipeline detected.\")\n",
        "        if r.get(\"extra\", {}).get(\"fft_ratio\", 0) > 1.2:\n",
        "            art_diag[\"hypotheses\"].append(\"[Signal] Elevated high-freq noise; potential spatial watermark present.\")\n",
        "        diagnosis.append(art_diag)\n",
        "    return diagnosis\n",
        "\n",
        "log(\"Diagnosis engine ready.\", \"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results-intro"
      },
      "source": [
        "#@title ðŸ“Š Phase 5: Results & Evidence Bundle\n",
        "\n",
        "**Output:**\n",
        "1. **Brutalist Report:** High-level summary of all artifacts.\n",
        "2. **Evidence Bundle:** JSON file for archival into the **Sovereign Evidence Vault**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "results-code"
      },
      "outputs": [],
      "source": [
        "#@title Run Final Audit\n",
        "if not UPLOADED_FILES: \n",
        "    log(\"Upload artifacts first.\", \"WARN\")\n",
        "else:\n",
        "    results = [scan_file(n, b) for n, b in UPLOADED_FILES.items()]\n",
        "    diag = get_diagnosis(results)\n",
        "    \n",
        "    table = \"<table class='artifex-table'><thead><tr><th>File</th><th>Flags</th><th>Hypothesis</th></tr></thead><tbody>\"\n",
        "    for r, d in zip(results, diag):\n",
        "        flags = \", \".join(r[\"flags\"]) if r[\"flags\"] else \"None\"\n",
        "        hyps = \"<br/>\".join(d[\"hypotheses\"]) if d[\"hypotheses\"] else \"Baseline Nominal\"\n",
        "        table += f\"<tr><td>{r['identity']['name']}</td><td>{flags}</td><td>{hyps}</td></tr>\"\n",
        "    table += \"</tbody></table>\"\n",
        "    \n",
        "    wps = [\n",
        "        (\"Activation Oracles (Anthropic, 2025)\", \"Latent intent detection.\"),\n",
        "        (\"The Setzer Protocol (ARTIFEX, 2025)\", \"Anti-Limerence steering.\"),\n",
        "        (\"UK AISI International Report (2025)\", \"Safety benchmarks.\")\n",
        "    ]\n",
        "    \n",
        "    display(HTML(brutalist_explainer_html(\n",
        "        \"H4RB1NG3R Multimodal Forensic Report\", \n",
        "        table, \n",
        "        \"Standard triage based on heuristic anomaly flags.\",\n",
        "        \"Artifact integrity verified via SHA256. Metadata suggests no acute tampering unless flagged.\",\n",
        "        wps\n",
        "    )))\n",
        "    \n",
        "    with open(\"evidence_bundle.json\", \"w\") as f:\n",
        "        json.dump(results, f)\n",
        "    log(\"Evidence bundle exported to evidence_bundle.json\", \"OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "watermark"
      },
      "outputs": [],
      "source": [
        "#@title Environment Tracking (%watermark)\n",
        "%load_ext watermark\n",
        "%watermark -v -p numpy,pandas,sklearn,torch,transformers,exifread,librosa\n",
        "log(\"Audit Sealed.\", \"LOCK\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}